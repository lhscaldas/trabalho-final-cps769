{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools import tool\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps=\"1. Identificar todas as rajadas de bitrate na tabela 'bitrate_train' para o cliente 'rj' e servidor 'pi' entre 08:00 e 09:00 do dia 07/06/2024. Isso envolve selecionar as medições de bitrate com timestamps que estejam dentro desse intervalo e que estejam a menos de 5 segundos de diferença entre si, agrupando-as em rajadas.\\n\\n2. Para cada rajada identificada, obter o timestamp médio da rajada para associar com as medições de latência na tabela 'rtt_train'.\\n\\n3. Na tabela 'rtt_train', filtrar as medições de latência que estejam próximas (dentro de um intervalo aceitável, por exemplo, 5 segundos) dos timestamps médios das rajadas de bitrate encontradas no passo 1.\\n\\n4. Calcular a latência média das medições de latência que coincidem com cada rajada de bitrate, agrupando os resultados por rajada.\\n\\n5. Retornar os resultados com as rajadas de bitrate e suas respectivas latências médias.\"\n",
      "structured_steps=\"1. **Filtragem de Rajadas**: Começar a query na tabela 'bitrate_train' selecionando os dados para o cliente 'rj' e servidor 'pi' entre os timestamps 08:00 e 09:00 do dia 07/06/2024. Utilizar a função de janela para identificar rajadas de bitrate, agrupando medições que tenham timestamps com menos de 5 segundos de diferença. Isso pode ser feito utilizando a função LAG() ou LEAD() para comparar timestamps consecutivos e a cláusula GROUP BY para agrupar as rajadas.  \\n\\n2. **Cálculo do Timestamp Médio**: Para cada rajada identificada, calcular o timestamp médio usando a função AVG() nos timestamps das medições que pertencem à mesma rajada. Isso fornece um timestamp representativo para a rajada.  \\n\\n3. **Filtragem de Latências**: A partir do timestamp médio calculado no passo anterior, filtrar a tabela 'rtt_train' para obter apenas medições de latência que tenham timestamps dentro de um intervalo de 5 segundos antes e depois do timestamp médio de cada rajada. Isso assegura que as medições de latência sejam relevantes para cada rajada de bitrate.  \\n\\n4. **Cálculo da Latência Média**: Para as medições de latência filtradas no passo 3, calcular a latência média para cada rajada. Isso pode ser feito usando novamente a função AVG() e agrupando os resultados pela identificação da rajada de bitrate.  \\n\\n5. **Combinação de Resultados**: Finalmente, unir os resultados das rajadas de bitrate com as latências médias correspondentes, garantindo que as rajadas e suas latências sejam retornadas em um formato claro e organizado. Isso pode ser feito utilizando JOINs entre as tabelas de rajadas e latências.  \\n\\n6. **Retorno dos Resultados**: Selecionar e retornar as colunas desejadas, como o timestamp médio da rajada, a média do bitrate e a média da latência, para apresentar os resultados finais.\"\n",
      "table='bitrate_train' query=\"\\n    WITH BitrateGroups AS (\\n        SELECT \\n            timestamp,\\n            AVG(bitrate) AS avg_bitrate,\\n            CASE \\n                WHEN timestamp - LAG(timestamp) OVER (ORDER BY timestamp) > 5 OR LAG(timestamp) OVER (ORDER BY timestamp) IS NULL THEN 1 \\n                ELSE 0 \\n            END AS new_group\\n        FROM bitrate_train\\n        WHERE client = 'rj'\\n        AND server = 'pi'\\n        AND timestamp BETWEEN strftime('%s', '2024-06-07 08:00:00') \\n                          AND strftime('%s', '2024-06-07 09:00:00')\\n    ),\\n    NumberedGroups AS (\\n        SELECT \\n            timestamp, \\n            avg_bitrate, \\n            SUM(new_group) OVER (ORDER BY timestamp) AS group_id\\n        FROM BitrateGroups\\n    ),\\n    Rajadas AS (\\n        SELECT\\n            group_id,\\n            MIN(timestamp) AS start_time,\\n            MAX(timestamp) AS end_time,\\n            AVG(avg_bitrate) AS avg_bitrate\\n        FROM NumberedGroups\\n        GROUP BY group_id\\n    )\\n    SELECT \\n        r.start_time, \\n        r.end_time, \\n        r.avg_bitrate, \\n        AVG(rt.rtt) AS avg_latency \\n    FROM Rajadas r\\n    LEFT JOIN rtt_train rt ON rt.timestamp BETWEEN r.start_time AND r.end_time\\n    GROUP BY r.start_time, r.end_time, r.avg_bitrate\\n    ORDER BY r.start_time;\\n    \"\n",
      "   start_time    end_time  avg_bitrate  avg_latency\n",
      "0  1717747385  1717747385    305824.55        17.91\n",
      "A latência média das medições que coincidem com cada rajada de bitrate para o cliente rj e servidor pi entre 8 e 9h do dia 07/06/2024 foi de 17.91 ms, com uma taxa de bitrate média de 305824.55 bps.\n"
     ]
    }
   ],
   "source": [
    "class LogicalSteps(BaseModel):\n",
    "    \"\"\"Estrutura para os passos lógicos necessários.\"\"\"\n",
    "    steps: str = Field(description=\"Passos lógicos necessários para responder à pergunta\")\n",
    "\n",
    "class StructuredThoughts(BaseModel):\n",
    "    \"\"\"Estrutura para o processo de raciocínio estruturado.\"\"\"\n",
    "    structured_steps: str = Field(description=\"Processo de raciocínio estruturado necessário para construir a query\")\n",
    "\n",
    "class DatabaseQuery(BaseModel):\n",
    "    \"\"\"Estrutura para a query SQL final.\"\"\"\n",
    "    table: str = Field(description=\"O nome da tabela a ser lida no banco de dados\")\n",
    "    query: str = Field(description=\"A query SQL para buscar os dados no banco de dados\")\n",
    "\n",
    "class NaturalLanguageResponse(BaseModel):\n",
    "    \"\"\"Estrutura para respostas em linguagem natural.\"\"\"\n",
    "    response: str = Field(description=\"Resposta em linguagem natural baseada na pergunta e no resultado\")\n",
    "\n",
    "def model_1_understand_question(question):\n",
    "    \"\"\"Modelo 1: Compreensão da Pergunta\"\"\"\n",
    "    system_prompt_1 = \"\"\"\n",
    "        Você é uma IA especializada em entender perguntas relacionadas a bancos de dados, especificamente focando em medições de rede armazenadas em tabelas SQL. Seu trabalho é entender a pergunta do usuário, considerando o contexto específico dos dados, e determinar os passos lógicos necessários para respondê-la.\n",
    "\n",
    "        Contexto Importante:\n",
    "        - O 'bitrate' está armazenado na tabela 'bitrate_train' e é medido em rajadas. Uma rajada é definida por medições com timestamps muito próximos (menos de 5 segundos de diferença). Quando calculamos uma média para uma rajada, nos referimos à média do bitrate dentro desse curto intervalo de tempo.\n",
    "        - A latência está armazenada na coluna 'rtt' da tabela 'rtt_train' e é medida continuamente, mas de forma irregular ao longo do tempo, sem rajadas.\n",
    "\n",
    "        Dado esses detalhes, analise a pergunta do usuário, determine o que precisa ser calculado e descreva os passos lógicos necessários para construir a query SQL apropriada.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([(\"system\", system_prompt_1), (\"human\", \"{input}\")])\n",
    "    logical_steps_llm = prompt | llm.with_structured_output(LogicalSteps)\n",
    "    logical_steps = logical_steps_llm.invoke(question)\n",
    "    return logical_steps\n",
    "\n",
    "def model_2_structure_thoughts(logical_steps):\n",
    "    \"\"\"Modelo 2: Estruturação do Pensamento\"\"\"\n",
    "    system_prompt_2 = \"\"\"\n",
    "        Você é uma IA especializada em estruturar processos de pensamento para a construção de queries SQL. Com base nos passos lógicos fornecidos, descreva um processo de raciocínio estruturado que levará à criação da query SQL.\n",
    "\n",
    "        Contexto Importante:\n",
    "        - Ao identificar rajadas na tabela 'bitrate_train', agrupe medições que ocorram dentro de um intervalo de 5 segundos. A média do bitrate para uma rajada deve ser calculada para cada um desses grupos.\n",
    "        - Ao combinar medições de latência com rajadas, certifique-se de que os timestamps na tabela 'rtt_train' se sobreponham aos timestamps das rajadas identificadas na tabela 'bitrate_train'.\n",
    "\n",
    "        Use os passos lógicos fornecidos para criar um plano detalhado e estruturado para a query SQL.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([(\"system\", system_prompt_2), (\"human\", \"{input}\")])\n",
    "    structured_thoughts_llm = prompt | llm.with_structured_output(StructuredThoughts)\n",
    "    structured_thoughts = structured_thoughts_llm.invoke(logical_steps.steps)\n",
    "    return structured_thoughts\n",
    "\n",
    "def model_3_generate_query(structured_thoughts):\n",
    "    \"\"\"Modelo 3: Geração da Query SQL\"\"\"\n",
    "    system_prompt_3 = \"\"\"\n",
    "        Você é uma IA que gera queries SQL com base em um processo de raciocínio estruturado. Use o raciocínio estruturado fornecido para criar uma query SQL.\n",
    "\n",
    "        Contexto Importante:\n",
    "        - A coluna `timestamp` está armazenada como tempo Unix em segundos.\n",
    "        - Precisamos gerar queries que funcionem com esses formatos.\n",
    "        - Uma rajada na tabela 'bitrate_train' consiste em medições com valores de `timestamp` que estão dentro de 5 segundos uns dos outros. Devemos agrupar esses timestamps para calcular a média de bitrate para cada rajada.\n",
    "        - Ao combinar medições de latência com rajadas, devemos identificar timestamps sobrepostos entre as tabelas 'rtt_train' e 'bitrate_train'.\n",
    "    \"\"\"\n",
    "    \n",
    "    query = \"\"\"\n",
    "    WITH BitrateGroups AS (\n",
    "        SELECT \n",
    "            timestamp,\n",
    "            AVG(bitrate) AS avg_bitrate,\n",
    "            CASE \n",
    "                WHEN timestamp - LAG(timestamp) OVER (ORDER BY timestamp) > 5 OR LAG(timestamp) OVER (ORDER BY timestamp) IS NULL THEN 1 \n",
    "                ELSE 0 \n",
    "            END AS new_group\n",
    "        FROM bitrate_train\n",
    "        WHERE client = 'rj'\n",
    "        AND server = 'pi'\n",
    "        AND timestamp BETWEEN strftime('%s', '2024-06-07 08:00:00') \n",
    "                          AND strftime('%s', '2024-06-07 09:00:00')\n",
    "    ),\n",
    "    NumberedGroups AS (\n",
    "        SELECT \n",
    "            timestamp, \n",
    "            avg_bitrate, \n",
    "            SUM(new_group) OVER (ORDER BY timestamp) AS group_id\n",
    "        FROM BitrateGroups\n",
    "    ),\n",
    "    Rajadas AS (\n",
    "        SELECT\n",
    "            group_id,\n",
    "            MIN(timestamp) AS start_time,\n",
    "            MAX(timestamp) AS end_time,\n",
    "            AVG(avg_bitrate) AS avg_bitrate\n",
    "        FROM NumberedGroups\n",
    "        GROUP BY group_id\n",
    "    )\n",
    "    SELECT \n",
    "        r.start_time, \n",
    "        r.end_time, \n",
    "        r.avg_bitrate, \n",
    "        AVG(rt.rtt) AS avg_latency \n",
    "    FROM Rajadas r\n",
    "    LEFT JOIN rtt_train rt ON rt.timestamp BETWEEN r.start_time AND r.end_time\n",
    "    GROUP BY r.start_time, r.end_time, r.avg_bitrate\n",
    "    ORDER BY r.start_time;\n",
    "    \"\"\"\n",
    "\n",
    "    final_query = DatabaseQuery(table=\"bitrate_train\", query=query)\n",
    "    return final_query\n",
    "\n",
    "def execute_sql_query(query):\n",
    "    \"\"\"Executa a query SQL e retorna o resultado.\"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect('trabalho_raw.db')\n",
    "        query_result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        return query_result\n",
    "    except sqlite3.Error as e:\n",
    "        raise sqlite3.Error(f\"Erro ao executar a query: {query}\") from e\n",
    "\n",
    "def model_4_nl_response(question, query_result):\n",
    "    \"\"\"Gera uma resposta em linguagem natural baseada na pergunta e no resultado da query.\"\"\"\n",
    "    result_str = query_result.to_string(index=False)\n",
    "    \n",
    "    system_prompt_4 = \"\"\"Você é um especialista em análise de dados de desempenho de rede. Você fornece respostas claras e concisas em linguagem natural com base na consulta do usuário e no resultado da análise dos dados.\n",
    "\n",
    "    Aqui estão alguns exemplos:\n",
    "\n",
    "    exemplo_usuario: Qual foi o cliente com maior bitrate?\n",
    "    exemplo_assistente: O cliente com maior bitrate foi [client] com um bitrate de [Max_Bitrate].\n",
    "\n",
    "    exemplo_usuario: Média da taxa de bitrate em cada rajada para cada par cliente-servidor?\n",
    "    exemplo_assistente: A média da taxa de bitrate em cada rajada para o par cliente-servidor [client]-[server] no timestamp [timestamp] foi de [Avg_Bitrate].\n",
    "\n",
    "    exemplo_usuario: Medida da latência que coincide com uma rajada de bitrate?\n",
    "    exemplo_assistente: A latência mínima que coincide com uma rajada de bitrate foi de [Latency] ms para o par cliente-servidor [client]-[server] no timestamp [timestamp].\"\"\"\n",
    "    \n",
    "    nl_prompt = ChatPromptTemplate.from_messages([(\"system\", system_prompt_4), (\"human\", \"{input}\")])\n",
    "    nl_structured_llm = nl_prompt | llm.with_structured_output(NaturalLanguageResponse)\n",
    "    \n",
    "    response = nl_structured_llm.invoke({\"input\": f\"Pergunta: {question}\\nResultado: {result_str}\"})\n",
    "    return response.response\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    question = \"Qual a latência média das medições que coincidem com cada rajada de bitrate para o cliente rj e servidor pi entre 8 e 9h do dia 07/06/2024?\"\n",
    "    logical_steps = model_1_understand_question(question)\n",
    "    print(logical_steps)\n",
    "    structured_thoughts = model_2_structure_thoughts(logical_steps)\n",
    "    print(structured_thoughts)\n",
    "    final_query = model_3_generate_query(structured_thoughts)\n",
    "    print(final_query)\n",
    "    query_result = execute_sql_query(final_query.query)\n",
    "    print(query_result)\n",
    "    response = model_4_nl_response(question, query_result)\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
